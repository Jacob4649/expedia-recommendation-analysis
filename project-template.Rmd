---
title: "Customers - Opaque and Unexpected Decisions"
author: "Jacob Klimczak - 1008203436"
subtitle: "How surprising customer trends can lead to improved search recommendations"
date: March 31, 2022
output: 
  beamer_presentation:
    theme: "Pittsburgh"
    colortheme: "crane"
    fonttheme: "structurebold"
    slide_level: 2
classoption: "aspectratio=169"
fontsize: 11pt
urlcolor: blue
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(rpart)
library(partykit)

# set seed
set.seed(314159265)

# load data
expedia_data <- read_csv("ExpediaSearchData.csv")
```

## Introduction

Expedia, a popular travel website, has gathered information on property searches
on their platform between June $1^{st}$, 2021, and July $31^{st}, 2021$.

This data includes information about recommendations the site offered to its
customers, as well how they responded to these recommendations.

The data has been used to examine: 

- The feasibility of offering recommendations
based on information about the composition of the group the consumer is
travelling with. 

- To examine whether offering a discounted price actually makes
people more interested in a location. 

- To examine how much use the recommendations actually get.

## Objectives

- Determine whether there is an association between the number of adults,
children and infants in a group, and the price of the bookings they are
interested in.

- Determine whether the likelihood of a user clicking on a recommendation is
the same between price reduced and non-price reduced recommendations.

- Determine a range of plausible values for the likelihood of a user clicking on
a recommendation.

## Data Wrangling

- Each row was split into three new rows, one for each recommendation shown.
Each row included observations on: 
  - The number of clicks (**num_clicks**)\
  - The number of infants, children, and adults (**infant_count**, 
  **child_count**, **adult_count**)\ 
  - Whether the recommended listing was price reduced (**is_drr**)\
  - The price bucket of the recommendation (**price_bucket**).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# extract first recommendation from each row
first_rec <- expedia_data %>% 
  select(infant_count, child_count, adult_count, price_bucket1, num_clicks1,
         is_drr1) %>% rename(price_bucket = price_bucket1,
                             num_clicks = num_clicks1, is_drr = is_drr1)

# extract second recommendation from each row
second_rec <- expedia_data %>% 
  select(infant_count, child_count, adult_count, price_bucket2, num_clicks2,
         is_drr2) %>% rename(price_bucket = price_bucket2,
                             num_clicks = num_clicks2, is_drr = is_drr2)

# extract third recommendation from each row
third_rec <- expedia_data %>% 
  select(infant_count, child_count, adult_count, price_bucket3, num_clicks3,
         is_drr3) %>% rename(price_bucket = price_bucket3,
                             num_clicks = num_clicks3, is_drr = is_drr3)

# combine first, second, and third recommendations into single dataframe
recommendations <- rbind(first_rec, second_rec, third_rec)
```

\vspace{0.3cm}

- A new variable called **is_click** was added to indicate whether a user
clicked a recommendation. This variable was assigned a value of:
  - *TRUE* when **num_clicks** was greater than 0\
  - *FALSE* otherwise.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
recommendations <- recommendations %>% mutate(is_click =
  case_when(num_clicks > 0 ~ TRUE, TRUE ~ FALSE))
```

\vspace{0.3cm}

- All missing values (*NA*) were removed.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
recommendations <- recommendations %>% filter(!is.na(num_clicks) & 
  !is.na(is_click) & !is.na(infant_count) & !is.na(child_count) &
  !is.na(adult_count) & !is.na(is_drr) & !is.na(price_bucket))
```

## Preliminary Analysis

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# determine how many searches resulted in click
searches <- nrow(expedia_data)
clicks <- expedia_data %>% filter(num_clicks1 > 0 | num_clicks2 > 0
                                  | num_clicks3 > 0) %>% nrow()

# determine how many price reduced searches resulted in click
pr_searches <- recommendations %>% filter(is_drr == 1)
pr_searches_total <- pr_searches %>% nrow()
pr_searches_click <- pr_searches %>% filter(is_click) %>% nrow()

# determine how many non-price-reduced searches resulted in click
npr_searches <- recommendations %>% filter(is_drr == 1)
npr_searches_total <- pr_searches %>% nrow()
npr_searches_click <- pr_searches %>% filter(is_click) %>% nrow()
```

\center
  *Table 1: Number Of Clicks On Recommendations*
\center

\begin{center}
  \begin{tabular} {| c | c | c |}
    \hline
    & Searches & Resulted in Click \\
    \hline
    All & `r searches` & `r clicks` \\
    \hline
    Price-Reduced & `r pr_searches_total` & `r pr_searches_click` \\
    \hline
    Non-Price-Reduced & `r npr_searches_total` & `r npr_searches_click` \\
    \hline
  \end{tabular}
\end{center}

- *Table 1* suggests the number of recommendations clicked on and used by
customers may not be that high---indicating that questioning the number of
recommendations that are clicked may be an interesting idea.

- The number of non-price-reduced recommendations resulting in clicks
compared to the number of price-reduced recommendations resulting in clicks
is also surprising, and suggests that asking whether the two happen equally
often will yield interesting answers.

# Statistical Methods

## Can Price Be Predicted From Group Composition?

- To see if the composition of a group, and the price of the recommendations
they were interested in, were related, a *classification tree* was made. 

- It made predictions on the *price bucket* groups clicked on were based on the 
number people of different ages in the groups.

### Classification Tree

A system that makes predictions on the category inputs will fall in
by looking at what categories previously entered inputs with similar
characteristics fell in.

### Price Bucket

How expensive is the booking:

1. Cheapest 20% of bookings

2. Bottom 20%-40% of bookings

3. Middle 40%-60% of bookings

4. Upper 60%-80% of bookings

5. Most expensive 80%-100% of bookings

---

- Recommendations that were not clicked on were ignored

- 75% of clicked on recommendations were used to teach the tree what different
priced bookings looked like relative to the composition of the group clicking on
them.

- The remaining 25% tested the tree to see how accurate it was. (See *table 1*)

- If the tree is making accurate predictions, there may be a relationship 
between group composition and price, if not then it appears there may not be a 
strong relationship.

### *Table 1: Testing/Training Split Example*
\begin{center}
  \begin{tabular} {c | c} 
    \textcolor{blue}{Training} &  \textcolor{red}{Testing}
  \end{tabular}
  
  \begin{tabular}{ | c | c | c | c | c | }
    \hline
    Row & Price Bucket & \# of Adults & \# of Children & \# of Infants \\
    \hline
    \textcolor{blue}{1} & \textcolor{blue}{5} & \textcolor{blue}{2} & 
    \textcolor{blue}{0} & \textcolor{blue}{0} \\ 
    \hline
    \textcolor{blue}{2} & \textcolor{blue}{4} & \textcolor{blue}{2} & 
    \textcolor{blue}{2} & \textcolor{blue}{1} \\
    \hline
    \textcolor{blue}{3} & \textcolor{blue}{4} & \textcolor{blue}{2} & 
    \textcolor{blue}{2} & \textcolor{blue}{0} \\
    \hline
    \textcolor{red}{4} & \textcolor{red}{2} & \textcolor{red}{1} & 
    \textcolor{red}{2} & \textcolor{red}{0} \\
    \hline
  \end{tabular}
\end{center}

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# filter for recommendations that were clicked
rec_counts <- recommendations %>% filter(is_click)

# split into testing and training
size <- nrow(rec_counts) # number of rows total
proportion <- 0.75 # proportion of rows to use for training
training_size <- round(proportion * size) # number of rows for training
training_indices <- sample(1:size, size = training_size) # indices for training
rec_counts <- rec_counts %>% rowid_to_column() # add row id

# get training and testing datasets
counts_train <- rec_counts %>% filter(rowid %in% training_indices)
counts_test <- rec_counts %>% filter(!rowid %in% training_indices)

# build fitted tree
counts_tree <- rpart(
  price_bucket ~ infant_count + child_count + adult_count, 
  data = counts_train, method = "class", control = rpart.control(
    cp = 0.01, minsplit = 3
  )) # default trees don't even have terminal for each price_bucket

# test tree
counts_pred <- predict(counts_tree, counts_test, type = "class")

# bundle into dataframe
accuracy_tibble <- tibble(prediction = counts_pred, 
                          actual = counts_test$price_bucket)

# calculate accuracy
accuracy <- accuracy_tibble %>%
  summarize(accuracy = mean(prediction == actual)) %>%
  as.numeric()
```

## Do Price-Reduced Clicks Differ From Standard Clicks?

- 10 000 simulated scenarios assuming clients clicked on price-reduced
recommendations and non-price-reduced recommendations at same rate were
examined.

- Reality was examined and compared to these simulated scenarios to determine
whether price-reduced and non-price-reduced recommendations are clicked on at
the same rate in real life.

- If reality doesn't resemble many of the simulated scenarios, it's likely
price-reduced and non-price-reduced recommendations are clicked on at different
rates.

### Simulated Scenario
- Scenarios were simulated by taking existing data, and switching which
recommendations were price-reduced.

- Each simulation had similar characteristics to reality, and had the same
number of price-reduced and non-price-reduced rows as reality.

```{r, echo=FALSE, messages=FALSE, warning=FALSE}
# calculate difference in likelihood of click for reduced and non-reduced
sample_drr_diff <- recommendations %>% group_by(is_drr) %>%
  summarize(probability = mean(is_click), .groups = "drop") %>%
  summarize(difference = diff(probability)) %>%
  as.numeric()

# simulate for hypothesis test
repetitions <- 10000
simulated_values <- rep(NA, repetitions)

for (i in 1:repetitions) {
  sim_data <- recommendations %>% mutate(is_drr = sample(is_drr))
  
  sim_parameter <- sim_data %>% group_by(is_drr) %>%
    summarize(probability = mean(is_click), .groups = "drop") %>%
    summarize(difference = diff(probability)) %>%
    as.numeric()
  
  simulated_values[i] <- sim_parameter
}

# calculate p value with simulated values
drr_simulation <- tibble(difference = simulated_values)
more_extreme_drr_diff <- drr_simulation %>% 
  filter(abs(difference) >= abs(sample_drr_diff)) %>% nrow()

drr_p_value <- more_extreme_drr_diff / repetitions
```

## Roughly How Frequently Are Recommendations Clicked On At Least Once?

- This was examined by taking random groups out of the recommendations we have,
and looking at how frequently recommendations are clicked in those random
*subgroups*.

- There is a relationship between the range of frequencies in the subgroups, and
the range where the frequency of clicking recommendations is in real life.

- The range where 95% of subgroups fell within was examined, and used to
find a range the real frequency of clicking recommendations is likely inside.

### Subgroup

- Each *subgroup* has the same amount of items as the real group, but some items
are repeated more than once.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# take bootstrap samples
repetitions <- 10000
bootstrap_samples <- rep(NA, repetitions)
for (i in 1:repetitions) {
  sample <- recommendations %>% sample_n(nrow(recommendations), replace = TRUE)
  bootstrap_samples[i] <- sample %>% summarize(mean(is_click)) %>% as.numeric()
}

# create tibble
bootstrap_distribution <- tibble(proportion = bootstrap_samples)

# prepare to take confidence interval
confidence <- 0.95
first_quantile <- (1 - confidence) / 2
last_quantile <- 1 - first_quantile
lower_bound = quantile(bootstrap_distribution$proportion, first_quantile)
upper_bound = quantile(bootstrap_distribution$proportion, last_quantile)
```

# Results

## No Strong Relationship Between Group Composition And Booking Price

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# format accuracy for use below
accuracy_formatted <- round(accuracy * 10000) / 100
```

- The *classification tree* only correctly identified price buckets
`r accuracy_formatted`% of the time.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=1.75, fig.width=4, fig.align='center'}
# manipulate data to prepare for bar plot
adults <- recommendations %>% select(adult_count, price_bucket) %>%
  mutate(Age = "Adult") %>% rename(count = adult_count)

children <- recommendations %>% select(child_count, price_bucket) %>%
  mutate(Age = "Child") %>% rename(count = child_count)

infants <- recommendations %>% select(infant_count, price_bucket) %>%
  mutate(Age = "Infant") %>% rename(count = infant_count)

plot_data <- rbind(adults, children, infants) %>% 
  group_by(price_bucket, Age) %>%
  summarize(mean = mean(count))

# show bar plot
plot_data %>% ggplot(aes(x = Age, y = mean, fill = Age)) +
  geom_bar(stat = "identity") + facet_wrap(~price_bucket) + 
  labs(x = "Age of Group Member", 
       y = "Mean Number in Group") +
  theme(text = element_text(size = 7))
```

\center
  *Figure 1: Average Number of Each Age in Groups Clicking on Different Price*
  *Buckets*
\center

- They all look pretty similar (*fig. 1*). There appears to be no relationship 
between group composition and price bucket.

## Price-Reduced And Non-Price-Reduced Listings Are Treated Differently

```{r, echo=FALSE, message=FALSE, warning=FALSE}
drr_p_value_formatted <- round(drr_p_value * 10000) / 100
```

- Of the 10 000 simulated scenarios, only `r drr_p_value_formatted`% or
`r more_extreme_drr_diff` item were similar to the real life scenario.

- This provides moderate evidence that the price-reduced and non-price-reduced
listings are clicked on at different rates by customers.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.height=1.25, fig.width=4, fig.align='center'}
# show bar plot of how common each is in sample
recommendations %>% mutate(reduced = is_drr == 1) %>% group_by(reduced) %>%
  summarize(probability = mean(is_click)) %>%
  ggplot(aes(x = reduced, y = probability)) + geom_bar(stat = "identity",
                                                      fill = "darkgreen") +
  labs(x = "Price-Reduced", y = "Probability of Click") +
  theme(text = element_text(size = 7))
```

\center
  *Figure 2: Probability of Clicking Different Recommendations*
  *In Real Data* 
\center

- In *figure 2*, non-reduced listings were clicked almost 50% more than
price reduced ones. There is a clear difference in how often they are clicked.

## Clicks Aren't Likely

- If the calculations to find the range of values the probability of a click 
were repeated many times, 95% of the time the probability of a click would fall
within the range.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=5, fig.height=0.75}
# get number clicked and not clicked
clicked <- recommendations %>% filter(is_click) %>% nrow()
clicked_frac <- clicked / nrow(recommendations)
clicked_formatted <- round(clicked_frac * 10000) / 100


# plot probability in sample
recommendations %>% ggplot(aes(x = is_click)) + geom_bar(fill = "darkgreen") +
  labs(x = "Clicked", y = "Count") + theme(text = element_text(size = 7))
```

\center
  *Figure 3: Number of Recommendations Clicked*
\center

### Found Interval
- 95% interval: **[`r lower_bound`, `r upper_bound`]**.

- In the real data, `r clicked_formatted`% of the first three
recommendations were clicked.

- This is within the found interval.

## Conclusions

Give your main conclusions here. Follow the order of questions you presented. 

### Can't Try To Cater Prices To Group Composition
- As *figure 1* showed, group compositions are similar regardless of the price
of the location being booked.

- Trying to adjust recommendations to show more expensive venues to customers
without kids for instance, may not be effective, and I recommend against it.

- This is surprising, one might expect older families that potentially
have dual-incomes and had time to establish themselves to have more money 
to spend on vacation. 

- It is possible that solo travellers and childless couples are also able to 
spend money on large accommodations, while the financial drain of children makes
some families less able to spend, thus, evening the playing field.

---

### Discounted And Standard Price Locations Are Different

- While they are different, *figure 2* shows it may not be in the expected way.

- Evidence that the probabilities for clicking discounted and non-discounted
recommendations are not the same was found. 

- In the data, non-discounted recommendations are clicked almost 50% more often.

- I would recommend Expedia present fewer discounted recommendations.

- One reason for this surprising result, could be that people perceive
discounted locations as 'cheap' and 'second rate'. They may be worried about the
quality of locations that need to resort to discounts to attract customers.

---

### Recommendations Are Not Fully Utilized

- Only a small fraction of the first three recommendations are clicked on (1 in
16 at the high end, 1 in 25 on the low end).

- Recommendations may not be very valuable to Expedia, if they are so rarely
used.

- If Expedia wishes to continue providing recommendations, I recommend
Expedia invest immediately in further investigation into which factors make
a 'good' (i.e. clickable, results in transaction) recommendation. 

- It is clear that at the moment, recommendations do very little to help
Expedia.

## References and Acknowledgements

*The author would like to thank Amin Banihashemi for his helpful comments*
*and suggestions that immensely improved the visualizations in*
*this presentation.*

### References

\begin{thebibliography}{1}
\bibitem{dataset}
Woznica, Adam and Krasnodebski, Jan (2021)
\emph{Expedia Group RecTour Research Dataset}, 
http://ceur-ws.org/Vol-2974/invited1.pdf.
\end{thebibliography}
